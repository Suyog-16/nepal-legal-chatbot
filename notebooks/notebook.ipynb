{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8faa6b7d",
   "metadata": {},
   "source": [
    "# HuggingFace Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f281958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List, Dict\n",
    "import os\n",
    "import requests\n",
    "\n",
    "class HuggingFaceAPILLM(LLM):\n",
    "    api_url: str = \"https://router.huggingface.co/v1/chat/completions\"\n",
    "    api_key: str = os.environ[\"HF_TOKEN\"]\n",
    "    model: str = \"meta-llama/Meta-Llama-3-8B-Instruct:novita\"\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"huggingface_api\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        headers = {\"Authorization\": f\"Bearer {self.api_key}\"}\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "        }\n",
    "        response = requests.post(self.api_url, headers=headers, json=payload)\n",
    "        result = response.json()\n",
    "        return result[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e366f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "llm = HuggingFaceAPILLM()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbdfd76",
   "metadata": {},
   "source": [
    "# Chunking the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d607a149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2691"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "import glob\n",
    "\n",
    "data_dir = \"../data/processed/\"\n",
    "txt_files = glob.glob(os.path.join(data_dir, \"*.txt\"))\n",
    "\n",
    "documents = []\n",
    "for file in txt_files:\n",
    "    loader = TextLoader(file)\n",
    "    docs = loader.load()\n",
    "    documents.extend(docs)\n",
    "\n",
    "# %%\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "len(chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef339521",
   "metadata": {},
   "source": [
    "# Generating and storing Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe8746a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1287422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vector_store = FAISS.from_documents(chunks, embeddings_model)\n",
    "vector_store.save_local(\"../faiss_index\")  # stores locally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ef91e",
   "metadata": {},
   "source": [
    "# Prompt Template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75609d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are an expert on laws, codes, and acts. Answer like a lawyer helping a common citizen regarding laws.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer concisely and clearly.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f704f5",
   "metadata": {},
   "source": [
    "# Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01701f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15723/2827365189.py:12: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa.run(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To file for bankruptcy of your company, follow these steps:\\n\\n1. **Determine if you qualify**: Check if you or your creditors meet the eligibility criteria for filing a bankruptcy petition (typically, a creditor or group of creditors with at least 25% of the total debts or more than ₹500,000).\\n2. **Gather necessary documents**: Collect financial statements, tax returns, and other relevant documents that show your company's financial situation.\\n3. **Choose the right type of bankruptcy**: Decide whether you want to file for **Insolvency** (if your company is unable to pay its debts) or **Liquidation** (if your company is insolvent and needs to be wound up).\\n4. **Prepare the petition**: File a petition in the court, accompanied by the required documents, including:\\n\\t* A statement of your company's financial position\\n\\t* A list of creditors and their claims\\n\\t* A plan for handling the bankruptcy proceedings\\n5. **Submit the petition**: File the petition with the court and pay the required fees.\\n6. **Wait for the court's decision**: The court will review your petition and may appoint an insolvency professional to oversee the bankruptcy proceedings.\\n\\n**Who can file a bankruptcy petition?**\\n\\n* You (as the company's director or owner)\\n* A creditor with a claim of at least 25% of the total debts (if the debt amount is disclosed)\\n* A creditor with a claim of more than ₹500,000 (if the debt amount is not disclosed)\\n\\n**Where to file the petition?**\\n\\n* You can file the petition with the Bombay High Court (or the High Court of your respective state), depending on your company's location.\\n\\n**What happens after filing the petition?**\\n\\nThe court will review your petition and may appoint an insolvency professional to oversee the bankruptcy proceedings. The insolvency professional will help you and your creditors navigate the process and make decisions about the company's assets and liabilities.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "# %%\n",
    "query = \"How do i file for bankcrupcy of my company\"\n",
    "answer = qa.run(query)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0012a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
